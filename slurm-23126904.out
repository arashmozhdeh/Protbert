[2023-09-26 21:49:39,599] p4138845 {src/ppi_finetuning.py:152 ::       prepare_params()} -  INFO - Starting parsing arguments...
[2023-09-26 21:49:39,605] p4138845 {src/ppi_finetuning.py:155 ::       prepare_params()} -  INFO - Finishing parsing arguments.
/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:151: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.
  rank_zero_deprecation(
/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:96: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=10)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.
  rank_zero_deprecation(
/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:171: LightningDeprecationWarning: Setting `Trainer(weights_summary=None)` is deprecated in v1.5 and will be removed in v1.7. Please set `Trainer(enable_model_summary=False)` instead.
  rank_zero_deprecation(
Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[2023-09-26 21:50:02,605] p4138845 {/home/arash.mozhdehi/GPU_STEP/STEP-main/src/modeling/ProtBertPPIModel.py:211 ::       freeze_encoder()} -  INFO - -- Freezing encoder model
[2023-09-26 21:50:02,608] p4138845 {src/ppi_finetuning.py:213 ::                 main()} -  INFO - Starting training.
/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 80 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Training: 0it [00:00, ?it/s]Training:   0%|          | 0/1228 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/1228 [00:00<?, ?it/s] inputs_A inputs_A {'input_ids': tensor([[ 2, 21, 13,  ...,  0,  0,  0],
        [ 2, 21, 10,  ..., 10, 10,  3],
        [ 2, 21, 14,  ...,  0,  0,  0],
        ...,
        [ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21, 12,  ...,  0,  0,  0],
        [ 2, 21,  5,  ...,  0,  0,  0]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}
inputs_B {'input_ids': tensor([[ 2, 21, 13,  ...,  0,  0,  0],
        [ 2, 21, 10,  ..., 10, 10,  3],
        [ 2, 21, 14,  ...,  0,  0,  0],
        ...,
        [ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21, 12,  ...,  0,  0,  0],
        [ 2, 21,  5,  ...,  0,  0,  0]], device='cuda:1'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:1')}
inputs_B {'input_ids': tensor([[ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21,  6,  ...,  0,  0,  0],
        ...,
        [ 2, 21,  8,  ...,  0,  0,  0],
        [ 2, 21, 15,  ...,  0,  0,  0],
        [ 2, 21, 10,  ...,  0,  0,  0]], device='cuda:1'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:1')}
targets {'labels': tensor([0, 1, 0, 1], device='cuda:0')}
{'input_ids': tensor([[ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21,  6,  ...,  0,  0,  0],
        [ 2, 21,  6,  ...,  0,  0,  0],
        ...,
        [ 2, 21,  8,  ...,  0,  0,  0],
        [ 2, 21, 15,  ...,  0,  0,  0],
        [ 2, 21, 10,  ...,  0,  0,  0]], device='cuda:1'), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        ...,
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0],
        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:1')}
targets {'labels': tensor([0, 1, 0, 1], device='cuda:1')}
Traceback (most recent call last):
  File "src/ppi_finetuning.py", line 271, in <module>
    main(params)
  File "src/ppi_finetuning.py", line 218, in main
    trainer.fit(model)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 770, in fit
    self._call_and_handle_interrupt(
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 723, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 811, in _fit_impl
    results = self._run(model, ckpt_path=self.ckpt_path)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1236, in _run
    results = self._run_stage()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1323, in _run_stage
    return self._run_train()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1353, in _run_train
    self.fit_loop.run()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 266, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 208, in advance
    batch_output = self.batch_loop.run(batch, batch_idx)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py", line 88, in advance
    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 204, in run
    self.advance(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 203, in advance
    result = self._run_optimization(
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 249, in _run_optimization
    closure()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 148, in __call__
    self._result = self.closure(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 134, in closure
    step_output = self._step_fn()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py", line 427, in _training_step
    training_step_output = self.trainer._call_strategy_hook("training_step", *step_kwargs.values())
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1765, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/strategies/dp.py", line 125, in training_step
    return self.model(*args, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 171, in forward
    outputs = self.parallel_apply(replicas, inputs, kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py", line 181, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 89, in parallel_apply
    output.reraise()
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/_utils.py", line 543, in reraise
    raise exception
ValueError: Caught ValueError in replica 0 on device 0.
Original Traceback (most recent call last):
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py", line 64, in _worker
    output = module(*input, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/overrides/data_parallel.py", line 64, in forward
    output = super().forward(*inputs, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/pytorch_lightning/overrides/base.py", line 82, in forward
    output = self.module.training_step(*inputs, **kwargs)
  File "/home/arash.mozhdehi/GPU_STEP/STEP-main/src/modeling/ProtBertPPIModel.py", line 381, in training_step
    train_loss, trues, preds = self.__single_step(batch)
  File "/home/arash.mozhdehi/GPU_STEP/STEP-main/src/modeling/ProtBertPPIModel.py", line 363, in __single_step
    loss = self.loss_bce_with_integrated_sigmoid(classifier_output, targets)
  File "/home/arash.mozhdehi/GPU_STEP/STEP-main/src/modeling/ProtBertPPIModel.py", line 288, in loss_bce_with_integrated_sigmoid
    return self._loss_bce_with_integrated_sigmoid(predictions["logits"], targets["labels"].float())
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 720, in forward
    return F.binary_cross_entropy_with_logits(input, target,
  File "/home/arash.mozhdehi/software1/miniconda3/envs/STEP1/lib/python3.8/site-packages/torch/nn/functional.py", line 3160, in binary_cross_entropy_with_logits
    raise ValueError("Target size ({}) must be the same as input size ({})".format(target.size(), input.size()))
ValueError: Target size (torch.Size([4])) must be the same as input size (torch.Size([8]))

